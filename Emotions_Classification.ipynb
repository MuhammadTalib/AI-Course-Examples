{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotions Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoiWlJAL0Osk5+1TINOxxd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadTalib/AI-Course-Examples/blob/master/Emotions_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "323SoN6ZMMfj",
        "outputId": "9f8b4ef9-32c6-4bd3-ca85-e944725ff04a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecudI906Lrx0",
        "outputId": "57bfd368-182f-4496-ed2a-2ea0c307af0c"
      },
      "source": [
        "!pip install trax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting trax\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/92/3ec523cf1307ba89b35e0e278d97ebe4f5197c352fd8643a70df89ff16e4/trax-1.3.9-py2.py3-none-any.whl (629kB)\n",
            "\r\u001b[K     |▌                               | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 9.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 2.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61kB 3.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 3.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 112kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 143kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 153kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 174kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 184kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 194kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 204kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 225kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 245kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 256kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 266kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 286kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 307kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 317kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 327kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 337kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 348kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 358kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 368kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 378kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 389kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 399kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 409kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 419kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 430kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 440kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 450kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 460kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 471kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 481kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 491kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 501kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 512kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 522kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 532kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 542kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 552kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 563kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 573kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 583kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 593kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 604kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 614kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 624kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from trax) (3.2.2)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from trax) (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trax) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from trax) (4.0.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from trax) (0.17.3)\n",
            "Collecting t5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/e4/e2dc66207464795aafecc5c8cef9a35b5c9a61b974ac60a2c306c12bfd4c/t5-0.9.1-py3-none-any.whl (152kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 14.4MB/s \n",
            "\u001b[?25hCollecting tensorflow-text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/ed/bbb51e9eccca0c2bfdf9df66e54cdff563b6f32daed9255da9b9a541368f/tensorflow_text-2.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 20.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trax) (1.4.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from trax) (5.4.8)\n",
            "Collecting funcsigs\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from trax) (0.2.13)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from trax) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from trax) (1.15.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from trax) (0.1.66+cuda110)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (0.10.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.1.6)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (21.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (3.12.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (4.41.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.23.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (5.1.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.16.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5->trax) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5->trax) (1.1.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 39.1MB/s \n",
            "\u001b[?25hCollecting seqio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/28/0a58b6eae1eaf11cac66969cb231826b8c4a9eef3479cc96ba085361af6d/seqio-0.0.5-py3-none-any.whl (249kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 27.2MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/85/e0004fa795fabe93f03db8dc6a99340beb9df7c7ac545d4527b43d358df1/tfds_nightly-4.3.0.dev202105280107-py3-none-any.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 40.1MB/s \n",
            "\u001b[?25hCollecting transformers>=2.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 39.2MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5->trax) (1.8.1+cu101)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5->trax) (2.9.1)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/10/37df0bc87ebf84e1414613176340e3aadc3697d2bd112bf63d3d4b1e848a/mesh_tensorflow-0.1.19-py3-none-any.whl (366kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 37.4MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5->trax) (3.2.5)\n",
            "Requirement already satisfied: tensorflow<2.6,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->trax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib->trax) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->trax) (56.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.53.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->trax) (3.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->t5->trax) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->t5->trax) (2018.9)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5->trax) (3.7.4.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 37.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax) (4.0.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5->trax) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (2.5.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.34.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.6.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (3.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5->trax) (7.1.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.30.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->trax) (3.1.0)\n",
            "Installing collected packages: sentencepiece, tensorflow-text, tfds-nightly, seqio, tokenizers, sacremoses, huggingface-hub, transformers, rouge-score, mesh-tensorflow, portalocker, sacrebleu, t5, funcsigs, trax\n",
            "Successfully installed funcsigs-1.0.2 huggingface-hub-0.0.8 mesh-tensorflow-0.1.19 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.5.1 sacremoses-0.0.45 sentencepiece-0.1.95 seqio-0.0.5 t5-0.9.1 tensorflow-text-2.5.0 tfds-nightly-4.3.0.dev202105280107 tokenizers-0.10.3 transformers-4.6.1 trax-1.3.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF0bPr4t3O0l",
        "outputId": "bbbde506-8b88-432e-d751-6334b4498ebf"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQXim1FtLY7M"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import trax\n",
        "import string\n",
        "import os\n",
        "import random as rnd\n",
        "from trax import layers as tl\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwlaMBIBL8wp"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/EmotionsDataset/train.txt\",names=[\"sentence\"])\n",
        "val_data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/EmotionsDataset/val.txt\",names=[\"sentence\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo56geTVMGOC"
      },
      "source": [
        "data[\"sentiment\"] = data.apply(lambda x: (x[\"sentence\"].split(\";\")[1]),axis=1)\n",
        "data[\"sentence\"] = data.apply(lambda x: (x[\"sentence\"].split(\";\")[0]),axis=1)\n",
        "\n",
        "val_data[\"sentiment\"] = val_data.apply(lambda x: (x[\"sentence\"].split(\";\")[1]),axis=1)\n",
        "val_data[\"sentence\"] = val_data.apply(lambda x: (x[\"sentence\"].split(\";\")[0]),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znVAIFIcMFAv"
      },
      "source": [
        "data[\"sentiment\"] = data[\"sentiment\"].map({'joy':0,'anger':1,'love':2,'sadness':3,'fear':4,'surprise':5})\n",
        "val_data[\"sentiment\"] = val_data[\"sentiment\"].map({'joy':0,'anger':1,'love':2,'sadness':3,'fear':4,'surprise':5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1pGLHUbMM1U",
        "outputId": "0e0bc9b5-dd1b-4a16-aa3e-42d4b6670569"
      },
      "source": [
        "data[\"sentiment\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        3\n",
              "1        3\n",
              "2        1\n",
              "3        2\n",
              "4        1\n",
              "        ..\n",
              "15995    3\n",
              "15996    3\n",
              "15997    0\n",
              "15998    1\n",
              "15999    3\n",
              "Name: sentiment, Length: 16000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "y2CCFrpLMo4a",
        "outputId": "08fbf902-84e8-43e7-e0e1-74e04d0a862a"
      },
      "source": [
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i feel like i am still looking at a blank canv...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i feel like a faithful servant</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am just feeling cranky and blue</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i can have for a treat or if i am feeling festive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  sentiment\n",
              "0  im feeling quite sad and sorry for myself but ...          3\n",
              "1  i feel like i am still looking at a blank canv...          3\n",
              "2                     i feel like a faithful servant          2\n",
              "3                  i am just feeling cranky and blue          1\n",
              "4  i can have for a treat or if i am feeling festive          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdEbJcdDMqqG",
        "outputId": "513d9007-5263-43cd-b595-7478fe6a678f"
      },
      "source": [
        "data['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5362\n",
              "3    4666\n",
              "1    2159\n",
              "4    1937\n",
              "2    1304\n",
              "5     572\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpXBIXplMtT8"
      },
      "source": [
        "def process_sentence(sentence):\n",
        "    sentence_tokens = word_tokenize(sentence)\n",
        "    sentences_clean = []\n",
        "    stemmer = PorterStemmer()\n",
        "    for word in sentence_tokens:\n",
        "        if (word not in stopwords.words('english') and word not in string.punctuation):\n",
        "            stem_word = stemmer.stem(word) # stemming word\n",
        "            sentences_clean.append(stem_word)\n",
        "    return sentences_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl0asgF2Mu2W",
        "outputId": "3edcf617-2f9b-48ec-d7ff-9cf7815f5634"
      },
      "source": [
        "process_sentence(\"im grabbing a minute to post i feel greedy wrong\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['im', 'grab', 'minut', 'post', 'feel', 'greedi', 'wrong']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aD9SZTk7NjCF",
        "outputId": "50aa120d-ccc7-4bf2-f435-67b1714848fd"
      },
      "source": [
        "vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2} \n",
        "\n",
        "for i in range(0,len(data)): \n",
        "    sent = data['sentence'][i]\n",
        "    processed_sent = process_sentence(sent)\n",
        "    for word in processed_sent:\n",
        "        if word not in vocab: \n",
        "            vocab[word] = len(vocab)\n",
        "    \n",
        "print(\"Total words in vocab are\",len(vocab))\n",
        "display(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words in vocab are 10378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'__PAD__': 0,\n",
              " '__</e>__': 1,\n",
              " '__UNK__': 2,\n",
              " 'didnt': 3,\n",
              " 'feel': 4,\n",
              " 'humili': 5,\n",
              " 'go': 6,\n",
              " 'hopeless': 7,\n",
              " 'damn': 8,\n",
              " 'hope': 9,\n",
              " 'around': 10,\n",
              " 'someon': 11,\n",
              " 'care': 12,\n",
              " 'awak': 13,\n",
              " 'im': 14,\n",
              " 'grab': 15,\n",
              " 'minut': 16,\n",
              " 'post': 17,\n",
              " 'greedi': 18,\n",
              " 'wrong': 19,\n",
              " 'ever': 20,\n",
              " 'nostalg': 21,\n",
              " 'fireplac': 22,\n",
              " 'know': 23,\n",
              " 'still': 24,\n",
              " 'properti': 25,\n",
              " 'grouchi': 26,\n",
              " 'ive': 27,\n",
              " 'littl': 28,\n",
              " 'burden': 29,\n",
              " 'late': 30,\n",
              " 'wasnt': 31,\n",
              " 'sure': 32,\n",
              " 'take': 33,\n",
              " 'milligram': 34,\n",
              " 'time': 35,\n",
              " 'recommend': 36,\n",
              " 'amount': 37,\n",
              " 'fallen': 38,\n",
              " 'asleep': 39,\n",
              " 'lot': 40,\n",
              " 'faster': 41,\n",
              " 'also': 42,\n",
              " 'like': 43,\n",
              " 'funni': 44,\n",
              " 'confus': 45,\n",
              " 'life': 46,\n",
              " 'teenag': 47,\n",
              " 'jade': 48,\n",
              " 'year': 49,\n",
              " 'old': 50,\n",
              " 'man': 51,\n",
              " 'petrona': 52,\n",
              " 'perform': 53,\n",
              " 'well': 54,\n",
              " 'made': 55,\n",
              " 'huge': 56,\n",
              " 'profit': 57,\n",
              " 'romant': 58,\n",
              " 'make': 59,\n",
              " 'suffer': 60,\n",
              " 'see': 61,\n",
              " 'mean': 62,\n",
              " 'someth': 63,\n",
              " 'run': 64,\n",
              " 'divin': 65,\n",
              " 'experi': 66,\n",
              " 'expect': 67,\n",
              " 'type': 68,\n",
              " 'spiritu': 69,\n",
              " 'encount': 70,\n",
              " 'think': 71,\n",
              " 'easiest': 72,\n",
              " 'dissatisfi': 73,\n",
              " 'low': 74,\n",
              " 'energi': 75,\n",
              " 'thirsti': 76,\n",
              " 'immens': 77,\n",
              " 'sympathi': 78,\n",
              " 'gener': 79,\n",
              " 'point': 80,\n",
              " 'possibl': 81,\n",
              " 'proto': 82,\n",
              " 'writer': 83,\n",
              " 'tri': 84,\n",
              " 'find': 85,\n",
              " 'write': 86,\n",
              " 'corner': 87,\n",
              " 'sign': 88,\n",
              " 'agent': 89,\n",
              " 'let': 90,\n",
              " 'alon': 91,\n",
              " 'publish': 92,\n",
              " 'contract': 93,\n",
              " 'preciou': 94,\n",
              " 'reassur': 95,\n",
              " 'anxieti': 96,\n",
              " 'side': 97,\n",
              " 'realli': 98,\n",
              " 'embarrass': 99,\n",
              " 'pretti': 100,\n",
              " 'pathet': 101,\n",
              " 'start': 102,\n",
              " 'sentiment': 103,\n",
              " 'doll': 104,\n",
              " 'child': 105,\n",
              " 'began': 106,\n",
              " 'collect': 107,\n",
              " 'vintag': 108,\n",
              " 'barbi': 109,\n",
              " 'sixti': 110,\n",
              " 'compromis': 111,\n",
              " 'skeptic': 112,\n",
              " 'valu': 113,\n",
              " 'everi': 114,\n",
              " 'unit': 115,\n",
              " 'work': 116,\n",
              " 'put': 117,\n",
              " 'irrit': 118,\n",
              " 'reject': 119,\n",
              " 'without': 120,\n",
              " 'anyon': 121,\n",
              " 'anyth': 122,\n",
              " 'say': 123,\n",
              " 'complet': 124,\n",
              " 'overwhelm': 125,\n",
              " 'two': 126,\n",
              " 'strategi': 127,\n",
              " 'help': 128,\n",
              " 'ground': 129,\n",
              " 'pour': 130,\n",
              " 'heart': 131,\n",
              " 'journal': 132,\n",
              " 'form': 133,\n",
              " 'letter': 134,\n",
              " 'god': 135,\n",
              " 'end': 136,\n",
              " 'list': 137,\n",
              " 'five': 138,\n",
              " 'thing': 139,\n",
              " 'grate': 140,\n",
              " 'amus': 141,\n",
              " 'delight': 142,\n",
              " 'abl': 143,\n",
              " 'chai': 144,\n",
              " 'lifelin': 145,\n",
              " 'support': 146,\n",
              " 'encourag': 147,\n",
              " 'great': 148,\n",
              " 'glad': 149,\n",
              " 'alreadi': 150,\n",
              " 'fuck': 151,\n",
              " 'though': 152,\n",
              " 'dont': 153,\n",
              " 'usual': 154,\n",
              " 'eat': 155,\n",
              " 'morn': 156,\n",
              " 'love': 157,\n",
              " 'wish': 158,\n",
              " 'best': 159,\n",
              " 'longer': 160,\n",
              " 'toler': 161,\n",
              " 'effect': 162,\n",
              " 'bm': 163,\n",
              " 'live': 164,\n",
              " 'fact': 165,\n",
              " 'turn': 166,\n",
              " 'bitter': 167,\n",
              " 'angri': 168,\n",
              " 'person': 169,\n",
              " 'alway': 170,\n",
              " 'particularli': 171,\n",
              " 'kind': 172,\n",
              " 'peopl': 173,\n",
              " 'stress': 174,\n",
              " 'inhibit': 175,\n",
              " 'els': 176,\n",
              " 'kitchen': 177,\n",
              " 'paint': 178,\n",
              " 'pictur': 179,\n",
              " 'becom': 180,\n",
              " 'defeat': 181,\n",
              " 'kinda': 182,\n",
              " 'appal': 183,\n",
              " 'need': 184,\n",
              " 'explain': 185,\n",
              " 'wide': 186,\n",
              " 'lenghth': 187,\n",
              " 'bodi': 188,\n",
              " 'measur': 189,\n",
              " 'etc': 190,\n",
              " 'pp': 191,\n",
              " 'superior': 192,\n",
              " 'dead': 193,\n",
              " 'chicken': 194,\n",
              " 'griev': 195,\n",
              " 'get': 196,\n",
              " 'giddi': 197,\n",
              " 'eleg': 198,\n",
              " 'perfectli': 199,\n",
              " 'fit': 200,\n",
              " 'pencil': 201,\n",
              " 'skirt': 202,\n",
              " 'rememb': 203,\n",
              " 'acut': 204,\n",
              " 'distress': 205,\n",
              " 'day': 206,\n",
              " 'seen': 207,\n",
              " 'heard': 208,\n",
              " 'read': 209,\n",
              " 'past': 210,\n",
              " 'coupl': 211,\n",
              " 'left': 212,\n",
              " 'impress': 213,\n",
              " 'compani': 214,\n",
              " 'climb': 215,\n",
              " 'hill': 216,\n",
              " 'frustrat': 217,\n",
              " 'id': 218,\n",
              " 'much': 219,\n",
              " 'pace': 220,\n",
              " 'entir': 221,\n",
              " 'cours': 222,\n",
              " 'factor': 223,\n",
              " 'never': 224,\n",
              " 'hamper': 225,\n",
              " 'dent': 226,\n",
              " 'imagin': 227,\n",
              " 'real': 228,\n",
              " 'scenario': 229,\n",
              " 'would': 230,\n",
              " 'emot': 231,\n",
              " 'connect': 232,\n",
              " 'enough': 233,\n",
              " 'total': 234,\n",
              " 'accept': 235,\n",
              " 'safe': 236,\n",
              " 'moral': 237,\n",
              " 'close': 238,\n",
              " 'prolong': 239,\n",
              " 'physic': 240,\n",
              " 'contact': 241,\n",
              " 'sex': 242,\n",
              " 'subsequ': 243,\n",
              " 'content': 244,\n",
              " 'creativ': 245,\n",
              " 'howev': 246,\n",
              " 'want': 247,\n",
              " 'caus': 248,\n",
              " 'less': 249,\n",
              " 'splendid': 250,\n",
              " 'self': 251,\n",
              " 'step': 252,\n",
              " 'away': 253,\n",
              " 'bit': 254,\n",
              " 'rude': 255,\n",
              " 'elderli': 256,\n",
              " 'gentleman': 257,\n",
              " 'ask': 258,\n",
              " 'gift': 259,\n",
              " 'christma': 260,\n",
              " 'mild': 261,\n",
              " 'greed': 262,\n",
              " 'protect': 263,\n",
              " 'small': 264,\n",
              " 'season': 265,\n",
              " 'word': 266,\n",
              " 'plan': 267,\n",
              " 'share': 268,\n",
              " 'everyday': 269,\n",
              " 'stori': 270,\n",
              " 'travel': 271,\n",
              " 'adventur': 272,\n",
              " 'inspir': 273,\n",
              " 'handmad': 274,\n",
              " 'creation': 275,\n",
              " 'tree': 276,\n",
              " 'got': 277,\n",
              " 'festiv': 278,\n",
              " 'spur': 279,\n",
              " 'book': 280,\n",
              " 'worn': 281,\n",
              " 'conceal': 282,\n",
              " 'brave': 283,\n",
              " 'pale': 284,\n",
              " 'perfect': 285,\n",
              " 'strongli': 286,\n",
              " 'passion': 287,\n",
              " 'jerk': 288,\n",
              " 'decid': 289,\n",
              " 'poke': 290,\n",
              " 'fun': 291,\n",
              " 'us': 292,\n",
              " 'discourag': 293,\n",
              " 'rob': 294,\n",
              " 'peter': 295,\n",
              " 'pay': 296,\n",
              " 'paul': 297,\n",
              " 'cow': 298,\n",
              " 'cant': 299,\n",
              " 'afford': 300,\n",
              " 'way': 301,\n",
              " 'listless': 302,\n",
              " 'new': 303,\n",
              " 'differ': 304,\n",
              " 'lost': 305,\n",
              " 'special': 306,\n",
              " 'mind': 307,\n",
              " 'worri': 308,\n",
              " 'sane': 309,\n",
              " 'felt': 310,\n",
              " 'mani': 311,\n",
              " 'said': 312,\n",
              " 'sam': 313,\n",
              " 'guarante': 314,\n",
              " 'use': 315,\n",
              " 'paragraph': 316,\n",
              " 'tell': 317,\n",
              " 'sad': 318,\n",
              " 'first': 319,\n",
              " 'home': 320,\n",
              " 'mine': 321,\n",
              " 'boat': 322,\n",
              " 'trip': 323,\n",
              " 'denmark': 324,\n",
              " 'stop': 325,\n",
              " 'cold': 326,\n",
              " 'hot': 327,\n",
              " 'dough': 328,\n",
              " 'found': 329,\n",
              " 'selfish': 330,\n",
              " 'spoil': 331,\n",
              " 'stymi': 332,\n",
              " 'wrote': 333,\n",
              " 'unsur': 334,\n",
              " 'might': 335,\n",
              " 'somewher': 336,\n",
              " 'unintend': 337,\n",
              " 'bag': 338,\n",
              " 'qaf': 339,\n",
              " 'look': 340,\n",
              " 'cryin': 341,\n",
              " 'jacynth': 342,\n",
              " 'lookin': 343,\n",
              " 'good': 344,\n",
              " 'feelin': 345,\n",
              " 'gorgeou': 346,\n",
              " 'rupaul': 347,\n",
              " 'skin': 348,\n",
              " 'scissor': 349,\n",
              " 'sister': 350,\n",
              " 'valentin': 351,\n",
              " 'sun': 352,\n",
              " 'fed': 353,\n",
              " 'kayl': 354,\n",
              " 'daddi': 355,\n",
              " 'gerl': 356,\n",
              " 'unkind': 357,\n",
              " 'u': 358,\n",
              " 'basic': 359,\n",
              " 'fake': 360,\n",
              " 'realm': 361,\n",
              " 'scienc': 362,\n",
              " 'fiction': 363,\n",
              " 'hate': 364,\n",
              " 'dad': 365,\n",
              " 'roof': 366,\n",
              " 'give': 367,\n",
              " 'excus': 368,\n",
              " 'asshol': 369,\n",
              " 'he': 370,\n",
              " 'provid': 371,\n",
              " 'unwelcom': 372,\n",
              " 'ill': 373,\n",
              " 'leav': 374,\n",
              " 'keep': 375,\n",
              " 'pleasantli': 376,\n",
              " 'surpris': 377,\n",
              " 'eas': 378,\n",
              " 'situat': 379,\n",
              " 'anymor': 380,\n",
              " 'vigor': 381,\n",
              " 'sexual': 382,\n",
              " 'activ': 383,\n",
              " 'come': 384,\n",
              " 'ye': 385,\n",
              " 'misspelt': 386,\n",
              " 'cum': 387,\n",
              " 'part': 388,\n",
              " 'begin': 389,\n",
              " 'fall': 390,\n",
              " 'mom': 391,\n",
              " 'grace': 392,\n",
              " 'warm': 393,\n",
              " 'smile': 394,\n",
              " 'nurtur': 395,\n",
              " 'heal': 396,\n",
              " 'talk': 397,\n",
              " 'brother': 398,\n",
              " 'law': 399,\n",
              " 'extrem': 400,\n",
              " 'popular': 401,\n",
              " 'one': 402,\n",
              " 'stiff': 403,\n",
              " 'ate': 404,\n",
              " 'could': 405,\n",
              " 'gentl': 406,\n",
              " 'tingl': 407,\n",
              " 'throughout': 408,\n",
              " 'almost': 409,\n",
              " 'place': 410,\n",
              " 'cellular': 411,\n",
              " 'level': 412,\n",
              " 'pressur': 413,\n",
              " 'young': 414,\n",
              " 'beauti': 415,\n",
              " 'thin': 416,\n",
              " 'depend': 417,\n",
              " 'trend': 418,\n",
              " 'girl': 419,\n",
              " 'rejuven': 420,\n",
              " 'butt': 421,\n",
              " 'implant': 422,\n",
              " 'sever': 423,\n",
              " 'week': 424,\n",
              " 'tortur': 425,\n",
              " 'hallucin': 426,\n",
              " 'move': 427,\n",
              " 'figur': 428,\n",
              " 'sound': 429,\n",
              " 'vibrat': 430,\n",
              " 'nearli': 431,\n",
              " 'finish': 432,\n",
              " 'detox': 433,\n",
              " 'amaz': 434,\n",
              " 'back': 435,\n",
              " 'former': 436,\n",
              " 'prayer': 437,\n",
              " 'other': 438,\n",
              " 'consid': 439,\n",
              " 'may': 440,\n",
              " 'deserv': 441,\n",
              " 'answer': 442,\n",
              " 'pain': 443,\n",
              " 'parent': 444,\n",
              " 'enrag': 445,\n",
              " 'violent': 446,\n",
              " 'roller': 447,\n",
              " 'coaster': 448,\n",
              " 'suppos': 449,\n",
              " 'unpleas': 450,\n",
              " 'truth': 451,\n",
              " 'havent': 452,\n",
              " 'faith': 453,\n",
              " 'dwell': 454,\n",
              " 'doubt': 455,\n",
              " 'uncertainti': 456,\n",
              " 'bought': 457,\n",
              " 'clearli': 458,\n",
              " 'makeup': 459,\n",
              " 'miser': 460,\n",
              " 'c': 461,\n",
              " 'proudest': 462,\n",
              " 'mum': 463,\n",
              " 'earth': 464,\n",
              " 'famili': 465,\n",
              " 'matter': 466,\n",
              " 'michel': 467,\n",
              " 'goe': 468,\n",
              " 'ballist': 469,\n",
              " 'necessarili': 470,\n",
              " 'f': 471,\n",
              " 'bomb': 472,\n",
              " 'necessari': 473,\n",
              " 'print': 474,\n",
              " 'ovari': 475,\n",
              " 'ach': 476,\n",
              " 'chri': 477,\n",
              " 'mostli': 478,\n",
              " 'took': 479,\n",
              " 'unimport': 480,\n",
              " 'stuff': 481,\n",
              " 'tire': 482,\n",
              " 'readi': 483,\n",
              " 'given': 484,\n",
              " 'unsuit': 485,\n",
              " 'imag': 486,\n",
              " 'blame': 487,\n",
              " 'result': 488,\n",
              " 'sit': 489,\n",
              " 'success': 490,\n",
              " 'manag': 491,\n",
              " 'stretch': 492,\n",
              " 'mxm': 493,\n",
              " 'canva': 494,\n",
              " 'achiev': 495,\n",
              " 'worthwhil': 496,\n",
              " 'usag': 497,\n",
              " 'money': 498,\n",
              " 'futur': 499,\n",
              " 'brief': 500,\n",
              " 'nay': 501,\n",
              " 'import': 502,\n",
              " 'honor': 503,\n",
              " 'influenc': 504,\n",
              " 'talent': 505,\n",
              " 'fulli': 506,\n",
              " 'aliv': 507,\n",
              " 'woman': 508,\n",
              " 'anger': 509,\n",
              " 'firey': 510,\n",
              " 'piec': 511,\n",
              " 'garbag': 512,\n",
              " 'leann': 513,\n",
              " 'thought': 514,\n",
              " 'miss': 515,\n",
              " 'drove': 516,\n",
              " 'dannika': 517,\n",
              " 'school': 518,\n",
              " 'rush': 519,\n",
              " 'greet': 520,\n",
              " 'hellip': 521,\n",
              " 'furiou': 522,\n",
              " 'shooter': 523,\n",
              " 'happi': 524,\n",
              " 'excit': 525,\n",
              " 'sinc': 526,\n",
              " 'learn': 527,\n",
              " 'show': 528,\n",
              " 'hors': 529,\n",
              " 'trust': 530,\n",
              " 'relax': 531,\n",
              " 'quiet': 532,\n",
              " 'handl': 533,\n",
              " 'frequent': 534,\n",
              " 'decemb': 535,\n",
              " 'done': 536,\n",
              " 'smug': 537,\n",
              " 'realiz': 538,\n",
              " 'everyth': 539,\n",
              " 'ok': 540,\n",
              " 'worthless': 541,\n",
              " 'struggl': 542,\n",
              " 'lay': 543,\n",
              " 'bed': 544,\n",
              " 'dark': 545,\n",
              " 'terrifi': 546,\n",
              " 'least': 547,\n",
              " 'meet': 548,\n",
              " 'airport': 549,\n",
              " 'arm': 550,\n",
              " 'today': 551,\n",
              " 'mood': 552,\n",
              " 'strang': 553,\n",
              " 'guess': 554,\n",
              " 'pass': 555,\n",
              " 'involv': 556,\n",
              " 'car': 557,\n",
              " 'accid': 558,\n",
              " 'bring': 559,\n",
              " 'present': 560,\n",
              " 'exam': 561,\n",
              " 'fli': 562,\n",
              " 'colour': 563,\n",
              " 'animos': 564,\n",
              " 'toward': 565,\n",
              " 'dog': 566,\n",
              " 'understand': 567,\n",
              " 'throw': 568,\n",
              " 'shitti': 569,\n",
              " 'shit': 570,\n",
              " 'paper': 571,\n",
              " 'wryli': 572,\n",
              " 'banal': 573,\n",
              " 'comedi': 574,\n",
              " 'error': 575,\n",
              " 'vital': 576,\n",
              " 'hear': 577,\n",
              " 'owner': 578,\n",
              " 'victim': 579,\n",
              " 'associ': 580,\n",
              " 'attorney': 581,\n",
              " 'goodby': 582,\n",
              " 'fam': 583,\n",
              " 'theyr': 584,\n",
              " 'cri': 585,\n",
              " 'heartless': 586,\n",
              " 'bitch': 587,\n",
              " 'hey': 588,\n",
              " 'spend': 589,\n",
              " 'anoth': 590,\n",
              " 'countri': 591,\n",
              " 'wont': 592,\n",
              " 'lili': 593,\n",
              " 'opportun': 594,\n",
              " 'last': 595,\n",
              " 'short': 596,\n",
              " 'month': 597,\n",
              " 'alba': 598,\n",
              " 'ton': 599,\n",
              " 'catch': 600,\n",
              " 'hard': 601,\n",
              " 'obtain': 602,\n",
              " 'high': 603,\n",
              " 'technic': 604,\n",
              " 'skill': 605,\n",
              " 'wushu': 606,\n",
              " 'asham': 607,\n",
              " 'somehow': 608,\n",
              " 'motiv': 609,\n",
              " 'saw': 610,\n",
              " 'kid': 611,\n",
              " 'whole': 612,\n",
              " 'heartedli': 613,\n",
              " 'despit': 614,\n",
              " 'tired': 615,\n",
              " 'spritz': 616,\n",
              " 'toner': 617,\n",
              " 'calm': 618,\n",
              " 'sooth': 619,\n",
              " 'effort': 620,\n",
              " 'requir': 621,\n",
              " 'better': 622,\n",
              " 'whether': 623,\n",
              " 'member': 624,\n",
              " 'colleg': 625,\n",
              " 'friend': 626,\n",
              " 'neighbor': 627,\n",
              " 'street': 628,\n",
              " 'even': 629,\n",
              " 'stranger': 630,\n",
              " 'soon': 631,\n",
              " 'on': 632,\n",
              " 'coron': 633,\n",
              " 'serious': 634,\n",
              " 'alright': 635,\n",
              " 'class': 636,\n",
              " 'combin': 637,\n",
              " 'unsuccess': 638,\n",
              " 'horribl': 639,\n",
              " 'grappl': 640,\n",
              " 'rare': 641,\n",
              " 'advanc': 642,\n",
              " 'stick': 643,\n",
              " 'rule': 644,\n",
              " 'onlin': 645,\n",
              " 'wouldnt': 646,\n",
              " 'prepar': 647,\n",
              " 'somebodi': 648,\n",
              " 'face': 649,\n",
              " 'group': 650,\n",
              " 'idea': 651,\n",
              " 'ugli': 652,\n",
              " 'inclin': 653,\n",
              " 'wear': 654,\n",
              " 'ratti': 655,\n",
              " 'jean': 656,\n",
              " 'sweatshirt': 657,\n",
              " 'dress': 658,\n",
              " 'pair': 659,\n",
              " 'heel': 660,\n",
              " 'hous': 661,\n",
              " 'boost': 662,\n",
              " 'esteem': 663,\n",
              " 'slightli': 664,\n",
              " 'definit': 665,\n",
              " 'bother': 666,\n",
              " 'buy': 667,\n",
              " 'homesick': 668,\n",
              " 'yet': 669,\n",
              " 'danc': 670,\n",
              " 'workout': 671,\n",
              " 'fabul': 672,\n",
              " 'eye': 673,\n",
              " 'touch': 674,\n",
              " 'assuredli': 675,\n",
              " 'return': 676,\n",
              " 'shall': 677,\n",
              " 'vain': 678,\n",
              " 'friday': 679,\n",
              " 'aw': 680,\n",
              " 'cramp': 681,\n",
              " 'honour': 682,\n",
              " 'call': 683,\n",
              " 'brotherhood': 684,\n",
              " 'begun': 685,\n",
              " 'apprehens': 686,\n",
              " 'thick': 687,\n",
              " 'black': 688,\n",
              " 'rain': 689,\n",
              " 'cloud': 690,\n",
              " 'storm': 691,\n",
              " 'sky': 692,\n",
              " 'town': 693,\n",
              " 'state': 694,\n",
              " 'reason': 695,\n",
              " 'fear': 696,\n",
              " 'unsaf': 697,\n",
              " 'shaken': 698,\n",
              " 'tsa': 699,\n",
              " 'quit': 700,\n",
              " 'pull': 701,\n",
              " 'croissant': 702,\n",
              " 'lunch': 703,\n",
              " 'awkward': 704,\n",
              " 'overcompens': 705,\n",
              " 'final': 706,\n",
              " 'companion': 707,\n",
              " 'especi': 708,\n",
              " 'lone': 709,\n",
              " 'disappoint': 710,\n",
              " 'blog': 711,\n",
              " 'img': 712,\n",
              " 'src': 713,\n",
              " 'http': 714,\n",
              " 'eager': 715,\n",
              " 'quilt': 716,\n",
              " 'horni': 717,\n",
              " 'poem': 718,\n",
              " 'uncomfort': 719,\n",
              " 'sens': 720,\n",
              " 'land': 721,\n",
              " 'rais': 722,\n",
              " 'son': 723,\n",
              " 'father': 724,\n",
              " 'ancestr': 725,\n",
              " 'shower': 726,\n",
              " 'question': 727,\n",
              " 'fantast': 728,\n",
              " 'confid': 729,\n",
              " 'movement': 730,\n",
              " 'effortlessli': 731,\n",
              " 'energet': 732,\n",
              " 'bounci': 733,\n",
              " 'gym': 734,\n",
              " 'outsid': 735,\n",
              " 'pram': 736,\n",
              " 'long': 737,\n",
              " 'walk': 738,\n",
              " 'often': 739,\n",
              " 'three': 740,\n",
              " 'strong': 741,\n",
              " 'burst': 742,\n",
              " 'tear': 743,\n",
              " 'devast': 744,\n",
              " 'releas': 745,\n",
              " 'seem': 746,\n",
              " 'rich': 747,\n",
              " 'space': 748,\n",
              " 'dump': 749,\n",
              " 'pumpkin': 750,\n",
              " 'spice': 751,\n",
              " 'latt': 752,\n",
              " 'coffe': 753,\n",
              " 'mayb': 754,\n",
              " 'badli': 755,\n",
              " 'she': 756,\n",
              " 'hyperchondria': 757,\n",
              " 'exagger': 758,\n",
              " 'habit': 759,\n",
              " 'openli': 760,\n",
              " 'clench': 761,\n",
              " 'assur': 762,\n",
              " 'right': 763,\n",
              " 'name': 764,\n",
              " 'utterli': 765,\n",
              " 'affirm': 766,\n",
              " 'perhap': 767,\n",
              " 'offic': 768,\n",
              " 'nice': 769,\n",
              " 'hair': 770,\n",
              " 'rebelli': 771,\n",
              " 'celebr': 772,\n",
              " 'eid': 773,\n",
              " 'wash': 774,\n",
              " 'sleep': 775,\n",
              " 'depriv': 776,\n",
              " 'night': 777,\n",
              " 'bloge': 778,\n",
              " 'amp': 779,\n",
              " 'cat': 780,\n",
              " 'lucki': 781,\n",
              " 'woke': 782,\n",
              " 'sick': 783,\n",
              " 'witch': 784,\n",
              " 'hunt': 785,\n",
              " 'repress': 786,\n",
              " 'memori': 787,\n",
              " 'therapi': 788,\n",
              " 'disgust': 789,\n",
              " 'race': 790,\n",
              " 'nation': 791,\n",
              " 'laugh': 792,\n",
              " 'bitterli': 793,\n",
              " 'knew': 794,\n",
              " 'forev': 795,\n",
              " 'mellow': 796,\n",
              " 'soft': 797,\n",
              " 'easi': 798,\n",
              " 'told': 799,\n",
              " 'indecis': 800,\n",
              " 'genr': 801,\n",
              " 'disservic': 802,\n",
              " 'resolv': 803,\n",
              " 'artif': 804,\n",
              " 'artist': 805,\n",
              " 'manitz': 806,\n",
              " 'draw': 807,\n",
              " 'circl': 808,\n",
              " 'dot': 809,\n",
              " 'bigger': 810,\n",
              " 'line': 811,\n",
              " 'accent': 812,\n",
              " 'mark': 813,\n",
              " 'spanish': 814,\n",
              " 'piss': 815,\n",
              " 'brazil': 816,\n",
              " 'bu': 817,\n",
              " 'steep': 818,\n",
              " 'mountain': 819,\n",
              " 'middl': 820,\n",
              " 'big': 821,\n",
              " 'wonder': 822,\n",
              " 'whimper': 823,\n",
              " 'unlov': 824,\n",
              " 'uncar': 825,\n",
              " 'certainli': 826,\n",
              " 'what': 827,\n",
              " 'curiou': 828,\n",
              " 'youd': 829,\n",
              " 'watch': 830,\n",
              " 'sorri': 831,\n",
              " 'humor': 832,\n",
              " 'foot': 833,\n",
              " 'door': 834,\n",
              " 'world': 835,\n",
              " 'trail': 836,\n",
              " 'fell': 837,\n",
              " 'whatev': 838,\n",
              " 'directli': 839,\n",
              " 'jealou': 840,\n",
              " 'insecur': 841,\n",
              " 'worthi': 842,\n",
              " 'sweet': 843,\n",
              " 'holiday': 844,\n",
              " 'dash': 845,\n",
              " 'emili': 846,\n",
              " 'dickinson': 847,\n",
              " 'exampl': 848,\n",
              " 'instead': 849,\n",
              " 'colon': 850,\n",
              " 'semi': 851,\n",
              " 'enhanc': 852,\n",
              " 'enjamb': 853,\n",
              " 'sonnet': 854,\n",
              " 'fatter': 855,\n",
              " 'remain': 856,\n",
              " 'control': 857,\n",
              " 'peanut': 858,\n",
              " 'butter': 859,\n",
              " 'bread': 860,\n",
              " 'imposs': 861,\n",
              " 'third': 862,\n",
              " 'hell': 863,\n",
              " 'needi': 864,\n",
              " 'neglect': 865,\n",
              " 'claim': 866,\n",
              " 'redeem': 867,\n",
              " 'beat': 868,\n",
              " 'head': 869,\n",
              " 'wall': 870,\n",
              " 'either': 871,\n",
              " 'intimid': 872,\n",
              " 'concept': 873,\n",
              " 'lit': 874,\n",
              " 'groggi': 875,\n",
              " 'routin': 876,\n",
              " 'view': 877,\n",
              " 'isnt': 878,\n",
              " 'that': 879,\n",
              " 'fine': 880,\n",
              " 'hold': 881,\n",
              " 'shock': 882,\n",
              " 'awe': 883,\n",
              " 'rumour': 884,\n",
              " 'st': 885,\n",
              " 'failur': 886,\n",
              " 'appreci': 887,\n",
              " 'arent': 888,\n",
              " 'anywher': 889,\n",
              " 'natur': 890,\n",
              " 'relationship': 891,\n",
              " 'chang': 892,\n",
              " 'distract': 893,\n",
              " 'regularli': 894,\n",
              " 'music': 895,\n",
              " 'invigor': 896,\n",
              " 'afterward': 897,\n",
              " 'tend': 898,\n",
              " 'practic': 899,\n",
              " 'shut': 900,\n",
              " 'w': 901,\n",
              " 'youtub': 902,\n",
              " 'specif': 903,\n",
              " 'tango': 904,\n",
              " 'shi': 905,\n",
              " 'mak': 906,\n",
              " 'opposit': 907,\n",
              " 'far': 908,\n",
              " 'pic': 909,\n",
              " 'lol': 910,\n",
              " 'weird': 911,\n",
              " 'slept': 912,\n",
              " 'okay': 913,\n",
              " 'earlier': 914,\n",
              " 'here': 915,\n",
              " 'coop': 916,\n",
              " 'restless': 917,\n",
              " 'weight': 918,\n",
              " 'tini': 919,\n",
              " 'unabl': 920,\n",
              " 'presenc': 921,\n",
              " 'fan': 922,\n",
              " 'current': 923,\n",
              " 'presid': 924,\n",
              " 'conserv': 925,\n",
              " 'enclos': 926,\n",
              " 'vers': 927,\n",
              " 'weigh': 928,\n",
              " 'odd': 929,\n",
              " 'complac': 930,\n",
              " 'vulner': 931,\n",
              " 'punish': 932,\n",
              " 'stupid': 933,\n",
              " 'chastis': 934,\n",
              " 'behav': 935,\n",
              " 'stay': 936,\n",
              " 'simpli': 937,\n",
              " 'cut': 938,\n",
              " 'everyon': 939,\n",
              " 'comfort': 940,\n",
              " 'solitud': 941,\n",
              " 'medit': 942,\n",
              " 'project': 943,\n",
              " 'nervou': 944,\n",
              " 'act': 945,\n",
              " 'bird': 946,\n",
              " 'air': 947,\n",
              " 'carefre': 948,\n",
              " 'manner': 949,\n",
              " 'revis': 950,\n",
              " 'repli': 951,\n",
              " 'appropri': 952,\n",
              " 'receiv': 953,\n",
              " 'offend': 954,\n",
              " 'die': 955,\n",
              " 'irrevoc': 956,\n",
              " 'gone': 957,\n",
              " 'alex': 958,\n",
              " 'matt': 959,\n",
              " 'regret': 960,\n",
              " 'visit': 961,\n",
              " 'educ': 962,\n",
              " 'educationg': 963,\n",
              " 'mama': 964,\n",
              " 'papa': 965,\n",
              " 'key': 966,\n",
              " 'hostil': 967,\n",
              " 'bore': 968,\n",
              " 'sew': 969,\n",
              " 'noth': 970,\n",
              " 'fabric': 971,\n",
              " 'origin': 972,\n",
              " 'fragranc': 973,\n",
              " 'freshen': 974,\n",
              " 'lightli': 975,\n",
              " 'scent': 976,\n",
              " 'underwear': 977,\n",
              " 'drawer': 978,\n",
              " 'gorgeous': 979,\n",
              " 'glamor': 980,\n",
              " 'girli': 981,\n",
              " 'apart': 982,\n",
              " 'push': 983,\n",
              " 'succeed': 984,\n",
              " 'wound': 985,\n",
              " 'process': 986,\n",
              " 'underway': 987,\n",
              " 'sometim': 988,\n",
              " 'ad': 989,\n",
              " 'antagon': 990,\n",
              " 'misunderstand': 991,\n",
              " 'reluct': 992,\n",
              " 'wholeheartedli': 993,\n",
              " 'tradit': 994,\n",
              " 'armistic': 995,\n",
              " 'remembr': 996,\n",
              " 'leg': 997,\n",
              " 'mile': 998,\n",
              " 'unfair': 999,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4xeNR-ONnqZ"
      },
      "source": [
        "def sent_to_tensor(sent, vocab_dict, unk_token='__UNK__', verbose=False):\n",
        "    \n",
        "    word_l = process_sentence(sent)\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"List of words from the processed tweet:\")\n",
        "        print(word_l)\n",
        "        \n",
        "    tensor_l = []\n",
        "    \n",
        "    unk_ID = vocab_dict[unk_token]\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"The unique integer ID for the unk_token is {unk_ID}\")\n",
        "        \n",
        "    for word in word_l:\n",
        "        word_ID = vocab_dict[word] if word in vocab_dict else unk_ID\n",
        "        tensor_l.append(word_ID) \n",
        "    \n",
        "    return tensor_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8FvmRb0HEv_",
        "outputId": "994fd185-22f0-4e31-e137-2cf1a023d95a"
      },
      "source": [
        "sent_to_tensor(\"im grabbing a minute to post i feel greedy wrong\",vocab,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of words from the processed tweet:\n",
            "['im', 'grab', 'minut', 'post', 'feel', 'greedi', 'wrong']\n",
            "The unique integer ID for the unk_token is 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14, 15, 16, 17, 4, 18, 19]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stISVDOYHLTi"
      },
      "source": [
        "def data_generator(data, batch_size, loop, vocab_dict, shuffle=False):\n",
        "    index_lines = list(range(0,len(data)))\n",
        "    \n",
        "    if shuffle:\n",
        "        rnd.shuffle(index_lines)\n",
        "        \n",
        "    stop = False\n",
        "    index = 0\n",
        "    data_len = len(data)\n",
        "    while not stop:  \n",
        "\n",
        "        batch = []\n",
        "        targets = []\n",
        "        for i in range(batch_size):\n",
        "      \n",
        "            if index >= data_len:\n",
        "              stop = True;\n",
        "              break;\n",
        "            sent = data['sentence'][index_lines[index]]\n",
        "            target = data['sentiment'][index_lines[index]]\n",
        "            # t = data['sentiment'][index_lines[index]]\n",
        "            # target[t]=1#data['sentiment'][index_lines[index]]\n",
        "            tensor = sent_to_tensor(sent, vocab_dict)\n",
        "            batch.append(tensor)\n",
        "            targets.append(target)\n",
        "            index = index + 1\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "        if stop:\n",
        "            break;\n",
        "\n",
        "        max_len = max([len(t) for t in batch]) \n",
        "        \n",
        "        tensor_pad_l = []\n",
        "        for tensor in batch:\n",
        "            n_pad = max_len - len(tensor)\n",
        "            pad_l = [0]*n_pad\n",
        "            tensor_pad = tensor + pad_l\n",
        "            tensor_pad_l.append(tensor_pad)\n",
        "\n",
        "        inputs = np.array(tensor_pad_l)\n",
        "        targets = np.array(targets)\n",
        "\n",
        "        example_weights = np.ones_like([1]*len(targets))\n",
        "        \n",
        "        yield inputs, targets, example_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "t5McmYXGcQ0u",
        "outputId": "991e4b78-1538-4926-f499-890522a4273f"
      },
      "source": [
        "val_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i feel like i am still looking at a blank canv...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i feel like a faithful servant</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am just feeling cranky and blue</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i can have for a treat or if i am feeling festive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>im having ssa examination tomorrow in the morn...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>i constantly worry about their fight against n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>i feel its important to share this info for th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>i truly feel that if you are passionate enough...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  sentiment\n",
              "0     im feeling quite sad and sorry for myself but ...          3\n",
              "1     i feel like i am still looking at a blank canv...          3\n",
              "2                        i feel like a faithful servant          2\n",
              "3                     i am just feeling cranky and blue          1\n",
              "4     i can have for a treat or if i am feeling festive          0\n",
              "...                                                 ...        ...\n",
              "1995  im having ssa examination tomorrow in the morn...          3\n",
              "1996  i constantly worry about their fight against n...          0\n",
              "1997  i feel its important to share this info for th...          0\n",
              "1998  i truly feel that if you are passionate enough...          0\n",
              "1999  i feel like i just wanna buy any cute make up ...          0\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTBXD5QbJ6S_"
      },
      "source": [
        "def train_generator(batch_size, shuffle = False):\n",
        "    return data_generator(data, batch_size, True, vocab, shuffle)\n",
        "\n",
        "def val_generator(batch_size, shuffle = False):\n",
        "    return data_generator(val_data, batch_size, True, vocab, shuffle)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcjWoFDj30WS",
        "outputId": "5f10a173-e269-4c82-f20b-3db65ef04195"
      },
      "source": [
        "next(val_generator(4, shuffle=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 739,    4,   99,   37,   35, 1679,  647,  899, 1279, 1364, 1516,\n",
              "            0,    0],\n",
              "        [   4, 1083,   12,  292, 5685,   54,    0,    0,    0,    0,    0,\n",
              "            0,    0],\n",
              "        [  14,   68,  169,  352,  128,    4, 1740,  890, 2503, 3187,  206,\n",
              "           59, 1573],\n",
              "        [ 340,  179,  674,    4, 2229,  346,  228,    0,    0,    0,    0,\n",
              "            0,    0]]), array([3, 2, 3, 0]), array([1, 1, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuJYqSjnK2xF"
      },
      "source": [
        "def classifier(vocab_size=len(vocab), embedding_dim=256, output_dim=6, mode='train'):\n",
        "        \n",
        "    embed_layer = tl.Embedding( vocab_size=vocab_size, d_feature=embedding_dim)\n",
        "    mean_layer = tl.Mean(axis=1)\n",
        "    \n",
        "    dense_output_layer = tl.Dense(output_dim)\n",
        "\n",
        "    log_softmax_layer = tl.LogSoftmax()\n",
        "    \n",
        "    model = tl.Serial(\n",
        "      embed_layer, # embedding layer\n",
        "      mean_layer, # mean layer\n",
        "      dense_output_layer, # dense output layer \n",
        "      log_softmax_layer  # log softmax layer\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X82iFOqtKAS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e45311d-d39e-452b-e8ea-c28be87d44fb"
      },
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "batch_size = 16\n",
        "rnd.seed(271)\n",
        "\n",
        "train_task = training.TrainTask(\n",
        "    labeled_data=train_generator(batch_size=batch_size, shuffle=True),\n",
        "    loss_layer=tl.CrossEntropyLoss(),\n",
        "    optimizer=trax.optimizers.Adam(0.01),\n",
        "    n_steps_per_checkpoint=10,\n",
        ")\n",
        "\n",
        "eval_task = training.EvalTask(\n",
        "    labeled_data=val_generator(batch_size=batch_size, shuffle=True),\n",
        "    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
        ")\n",
        "\n",
        "model = classifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4gcg_rW4rBo",
        "outputId": "b64e9eff-8261-4209-f199-0a824f1001be"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Serial[\n",
              "  Embedding_10378_256\n",
              "  Mean\n",
              "  Dense_6\n",
              "  LogSoftmax\n",
              "]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVsizrRUNsS8"
      },
      "source": [
        "def train_model(classifier, train_task, eval_task, n_steps, output_dir):\n",
        "    training_loop = training.Loop(\n",
        "                                classifier, # The learning model\n",
        "                                train_task, # The training task\n",
        "                                eval_tasks = eval_task, # The evaluation task\n",
        "                                output_dir = output_dir) # The output directory\n",
        "\n",
        "    training_loop.run(n_steps = n_steps)\n",
        "    return training_loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enMWOc6RPPps",
        "outputId": "dcada5a9-0100-4a7a-ffcc-2b5a4b4b6e78"
      },
      "source": [
        "output_dir = '~/model/'\n",
        "output_dir_expand = os.path.expanduser(output_dir)\n",
        "print(output_dir_expand)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/model/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZYvLXTY4Osi",
        "outputId": "51ed7aca-3036-4b22-b75e-899022c9a5c4"
      },
      "source": [
        "train_task"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<trax.supervised.training.TrainTask at 0x7f442ae93cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LiiDk26BVuo"
      },
      "source": [
        "# training_loop = None\n",
        "# train_model=None\n",
        "# train_task=None\n",
        "# eval_task=None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlBxtBYzOQzv",
        "outputId": "2759e556-ec73-4e62-9178-f52fb7b8074e"
      },
      "source": [
        "training_loop = train_model(model, train_task, eval_task, 50, output_dir_expand)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:304: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n",
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:317: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_count has been renamed to jax.process_count. This alias \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step    260: Ran 10 train steps in 9.90 secs\n",
            "Step    260: train CrossEntropyLoss |  0.69684011\n",
            "Step    260: eval  CrossEntropyLoss |  1.22330570\n",
            "Step    260: eval          Accuracy |  0.50000000\n",
            "\n",
            "Step    270: Ran 10 train steps in 5.40 secs\n",
            "Step    270: train CrossEntropyLoss |  0.63721842\n",
            "Step    270: eval  CrossEntropyLoss |  0.78763801\n",
            "Step    270: eval          Accuracy |  0.75000000\n",
            "\n",
            "Step    280: Ran 10 train steps in 3.59 secs\n",
            "Step    280: train CrossEntropyLoss |  0.53656149\n",
            "Step    280: eval  CrossEntropyLoss |  1.27938557\n",
            "Step    280: eval          Accuracy |  0.56250000\n",
            "\n",
            "Step    290: Ran 10 train steps in 5.92 secs\n",
            "Step    290: train CrossEntropyLoss |  0.69653559\n",
            "Step    290: eval  CrossEntropyLoss |  1.06231701\n",
            "Step    290: eval          Accuracy |  0.75000000\n",
            "\n",
            "Step    300: Ran 10 train steps in 2.59 secs\n",
            "Step    300: train CrossEntropyLoss |  0.63932592\n",
            "Step    300: eval  CrossEntropyLoss |  1.03542447\n",
            "Step    300: eval          Accuracy |  0.62500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zIppfq8BPai"
      },
      "source": [
        "%matplotlib notebook\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "E633N10Xd0Ra",
        "outputId": "38f2ea85-b428-4c6d-fa79-a1a1c53a4f6a"
      },
      "source": [
        "frame = pd.DataFrame(training_loop.history.get(\"eval\", \"metrics/CrossEntropyLoss\"), columns=\"Batch CrossEntropyLoss\".split())\n",
        "plt.plot(frame[\"CrossEntropyLoss\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4414a80350>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "-MvxngnbdoGO",
        "outputId": "7614c87c-3f6f-4969-9605-91279c354d1e"
      },
      "source": [
        "frame = pd.DataFrame(training_loop.history.get(\"eval\", \"metrics/Accuracy\"), columns=\"Batch Accuracy\".split())\n",
        "plt.plot(frame[\"Accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f44149d2190>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6AXFJShFULZ"
      },
      "source": [
        "def compute_accuracy(preds, y, y_weights):\n",
        "\n",
        "    preds = np.array([j for i in (preds == preds.max(axis=1)[:,None]).astype(int) for j in range(0,len(i)) if i[j]==1])\n",
        "\n",
        "    # is_pos =  preds[:, 1] > preds[:, 0] \n",
        "\n",
        "    is_correct = preds.astype(np.int32)\n",
        "    correct = is_correct == y\n",
        "\n",
        "    sum_weights = np.sum(y_weights)\n",
        "    \n",
        "    correct_float = correct.astype(np.float32)\n",
        "    print(\"correct_float\", correct_float)\n",
        "\n",
        "    weighted_correct_float = correct_float * y_weights\n",
        "    print(\"weighted_correct_float\", weighted_correct_float)\n",
        "\n",
        "    weighted_num_correct = np.sum(weighted_correct_float)\n",
        " \n",
        "    accuracy = weighted_num_correct / sum_weights\n",
        "\n",
        "    return accuracy, weighted_num_correct, sum_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Vl0IJ1OYY-"
      },
      "source": [
        "def test_model(generator, model):\n",
        "    \n",
        "    accuracy = 0.\n",
        "    total_num_correct = 0\n",
        "    total_num_pred = 0\n",
        "    \n",
        "    for batch in generator: \n",
        "        \n",
        "        inputs = batch[0]\n",
        "        targets = batch[1]\n",
        "        example_weight = batch[2]\n",
        "\n",
        "        pred = model(inputs)\n",
        "        \n",
        "        batch_accuracy, batch_num_correct, batch_num_pred = compute_accuracy(\n",
        "            pred, \n",
        "            targets, \n",
        "            example_weight)\n",
        "        print(\"batch_accuracy, batch_num_correct, batch_num_pred\", batch_accuracy, batch_num_correct, batch_num_pred)\n",
        "        \n",
        "        total_num_correct += batch_num_correct\n",
        "        \n",
        "        total_num_pred += batch_num_pred\n",
        "\n",
        "    accuracy = total_num_correct / total_num_pred\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RGWGFuKEpc0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPrxNjGE9-sC",
        "outputId": "ffa9258e-490d-42db-9e4d-b0a3a967646b"
      },
      "source": [
        "model = training_loop.eval_model\n",
        "accuracy = test_model(val_generator(16), model)\n",
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.9375 15.0 16\n",
            "correct_float [1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
            "weighted_correct_float [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
            "weighted_correct_float [0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.4375 7.0 16\n",
            "correct_float [1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.]\n",
            "weighted_correct_float [0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
            "weighted_correct_float [0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.]\n",
            "weighted_correct_float [1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
            "weighted_correct_float [1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
            "weighted_correct_float [1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
            "weighted_correct_float [0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5 8.0 16\n",
            "correct_float [1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
            "weighted_correct_float [1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.]\n",
            "weighted_correct_float [0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.9375 15.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0.]\n",
            "weighted_correct_float [0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.4375 7.0 16\n",
            "correct_float [1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.]\n",
            "weighted_correct_float [1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
            "weighted_correct_float [0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5 8.0 16\n",
            "correct_float [0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
            "weighted_correct_float [1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "weighted_correct_float [1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5 8.0 16\n",
            "correct_float [0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
            "weighted_correct_float [0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
            "weighted_correct_float [1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "weighted_correct_float [1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5 8.0 16\n",
            "correct_float [1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
            "weighted_correct_float [1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5 8.0 16\n",
            "correct_float [1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.9375 15.0 16\n",
            "correct_float [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
            "weighted_correct_float [0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
            "weighted_correct_float [1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
            "weighted_correct_float [0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
            "weighted_correct_float [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5 8.0 16\n",
            "correct_float [0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
            "weighted_correct_float [0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
            "weighted_correct_float [0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.8125 13.0 16\n",
            "correct_float [1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
            "weighted_correct_float [1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.5625 9.0 16\n",
            "correct_float [1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
            "weighted_correct_float [1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.6875 11.0 16\n",
            "correct_float [1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            "weighted_correct_float [1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.75 12.0 16\n",
            "correct_float [0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
            "weighted_correct_float [0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.9375 15.0 16\n",
            "correct_float [0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.875 14.0 16\n",
            "correct_float [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
            "weighted_correct_float [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.375 6.0 16\n",
            "correct_float [1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n",
            "correct_float [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "weighted_correct_float [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.9375 15.0 16\n",
            "correct_float [1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
            "weighted_correct_float [1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
            "batch_accuracy, batch_num_correct, batch_num_pred 0.625 10.0 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7155"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpXiQmrzGBTe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJOZtHVdHEQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5c3ba6-5bae-45eb-f3d5-983c6fcf03c5"
      },
      "source": [
        "sentence = \"i feel like a faithful servant\"\n",
        "output = predict(sentence)\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray([[5.66585732e+00, 1.68471947e+01, 3.46946716e-03,\n",
              "               1.54994755e+01, 1.52864580e+01, 1.36058655e+01]],            dtype=float32),\n",
              " DeviceArray(0.25166988, dtype=float32),\n",
              " DeviceArray(2, dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp7dEamFHQqs"
      },
      "source": [
        "##.map({'joy':0,'anger':1,'love':2,'sadness':3,'fear':4,'surprise':5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZzUm9GeKK9v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}